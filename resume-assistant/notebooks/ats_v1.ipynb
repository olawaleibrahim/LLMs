{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "from langchain_google_vertexai import ChatVertexAI\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate\n",
    ")\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langchain_google_community import DocAIParser\n",
    "from langchain_core.document_loaders.blob_loaders import Blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = os.getenv(\"PROJECT_ID\")\n",
    "REGION = os.getenv(\"REGION\")\n",
    "INDEX_NAME = os.getenv(\"INDEX_NAME\")\n",
    "INDEX_ID = os.getenv(\"INDEX_ID\")\n",
    "DB_USER= os.getenv(\"CLOUD_SQL_USER1\")\n",
    "DB_PASS = os.getenv(\"CLOUD_SQL_PASSWORD\")\n",
    "GCS_BUCKET_NAME = os.getenv(\"GCS_BUCKET_NAME\")\n",
    "DOC_PROCESSOR_NAME = os.getenv(\"DOC_PROCESSOR_NAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_webpage_content(url):\n",
    "    \"\"\"Scrapes the entire content of the given webpage.\"\"\"\n",
    "    headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to fetch page, status code: {response.status_code}\")\n",
    "        return None\n",
    "    \n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    page_content = soup.get_text(separator='\\n', strip=True)\n",
    "    \n",
    "    return page_content\n",
    "\n",
    "\n",
    "def get_json_from_result(result):\n",
    "    return json.loads(result.content[8:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [\n",
    "    \"https://www.linkedin.com/jobs/view/4157337860\",\n",
    "    \"https://job-boards.greenhouse.io/scaleai/jobs/4413274005\",\n",
    "    \"https://www.linkedin.com/jobs/view/4091428817\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(\n",
    "            content=(\n",
    "                \"You are a helpful assistant that helps to extract the job description from a corpus of words from a webpage\"\n",
    "                \"\"\"\n",
    "                You analyse the content provide, and extract only the job requirements and responsibilities.\n",
    "                The content contains other irrelevant text extracted from the web page. Your job is to output only \n",
    "                the job requirements and responsibilities, skills, company. Do not modify the original words in the job description.\n",
    "                Return the extracted job description only as a json object.\n",
    "                Example:\n",
    "                {\n",
    "                    \"job_description\": \"This is a job that does nothing\"\n",
    "                }\n",
    "                \"\"\"\n",
    "            )\n",
    "        ),\n",
    "        HumanMessagePromptTemplate.from_template(\n",
    "            \"Kindly extract the job description from this: {webpage_content}\"\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "ats_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(\n",
    "            content=(\n",
    "                \"You are a helpful assistant that helps review resumes for ATS compliance\"\n",
    "                \"\"\"You ensure that you use the provided job description to make the resume more ATS friendly \\n\n",
    "                Do not remove quantifiable metrics found in the resume experience, but only modify the resume to include the keywords found in the job_description \n",
    "                Ensure that the work experience essence is not lost in the resume content is retained while modifying the sentences to semnatically include keywords in the job description\\n\n",
    "                Provide only content that should go into the final resume and nothing extra\"\"\"\n",
    "                \"\"\"You always respond in a structured format with the following subheadings: \\n\n",
    "                1. Summary \\n\n",
    "                2. Experience \\n\n",
    "                3. Skills \\n\n",
    "                4. Missing Keywords \\n\n",
    "                5. In this section only, list changes made to the resume to make it ATS friendly that was previously missing \\n\n",
    "                \"\"\"\n",
    "            )\n",
    "        ),\n",
    "        HumanMessagePromptTemplate.from_template(\n",
    "            \"Make my resume and work experience more ATS friendly: \\n {resume_content} \\n using the job's description: \\n {job_description}\"\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_job_description(chat_template, web_url):\n",
    "\n",
    "    webpage_content = scrape_webpage_content(web_url)\n",
    "    chat_model = ChatVertexAI(model_name=\"gemini-1.5-pro\")\n",
    "    chain = chat_template | chat_model \n",
    "    result = chain.invoke({\"webpage_content\": webpage_content})\n",
    "    \n",
    "    # print(result.content)\n",
    "    content_json = get_json_from_result(result)\n",
    "    return content_json[\"job_description\"]\n",
    "\n",
    "\n",
    "def get_resume_content(filename=\"Olawale_Machine_Learning_Engineer_Template.pdf\"):\n",
    "    parser = DocAIParser(location=\"us\",\n",
    "                     processor_name=DOC_PROCESSOR_NAME,\n",
    "                     gcs_output_path=\"gs://{}/resume-assistant/data/output/dev/pdfs\".format(GCS_BUCKET_NAME))\n",
    "    inp_path = f\"gs://{GCS_BUCKET_NAME}/resume-assistant/data/input/dev/pdfs/{filename}\"\n",
    "    blob = Blob(path=inp_path)\n",
    "    docs = list(parser.lazy_parse(blob))\n",
    "    resume_content = \"\"\n",
    "    for doc in docs:\n",
    "        resume_content+=doc.page_content\n",
    "\n",
    "    return resume_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job1 = get_job_description(chat_template, urls[0])\n",
    "print(job1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_content = get_resume_content()\n",
    "print(resume_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_model = ChatVertexAI(model_name=\"gemini-1.5-pro\")\n",
    "ats_chain = ats_template | chat_model \n",
    "ats_result = ats_chain.invoke({\"job_description\": job1,\n",
    "                       \"resume_content\": resume_content})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ats_result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(job1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
