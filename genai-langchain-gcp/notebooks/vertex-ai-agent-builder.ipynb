{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain-google-vertexai langchain-google-community[vertexaisearch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain_google_vertexai import VertexAI\n",
    "\n",
    "\n",
    "llm = VertexAI(model_name=\"gemini-1.0-pro\",\n",
    "               temperature=0.8, max_output_tokens=128)\n",
    "template = \"\"\"Describe {plant}.\n",
    "    First, think whether {plant} exist.\n",
    "    If they {plant} don't exist, answer \"I don't have enough information about {plant}\".\n",
    "    Otherwise, give their title, a short summary and then talk about origin and cultivation.\n",
    "    After that, describe their physical characteristics.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Black Cucumbers\n",
      "\n",
      "### Do they exist?\n",
      "\n",
      "Black cucumbers are not widely recognized as a distinct variety. While there are cucumber cultivars with dark green or nearly black skin, true black cucumbers are not commonly found. \n",
      "\n",
      "Therefore, I don't have enough information about black cucumbers to provide a comprehensive description. However, I can share some insights about cucumber varieties with dark skin that might be mistaken for black cucumbers.\n",
      "\n",
      "### Dark-skinned Cucumber Varieties\n",
      "\n",
      "Several cucumber cultivars exhibit dark green skin that appears nearly black under certain lighting conditions. These include:\n",
      "\n",
      "* **Armenian Cucumber:** This heirloom variety has long, slender fruits with dark\n"
     ]
    }
   ],
   "source": [
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"plant\"],\n",
    "    template=template\n",
    ")\n",
    "chain = LLMChain(llm=llm,\n",
    "                 prompt=prompt_template)\n",
    "print(chain.run(plant=\"black cucumbers\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'plant': 'green cucumbers', 'text': '## Green Cucumbers\\n\\nGreen cucumbers are a type of cucumber that, as the name suggests, are green in color. They are the most common type of cucumber and are widely available in grocery stores and farmers markets.\\n\\n### Origin and Cultivation\\n\\nGreen cucumbers originated in India and have been cultivated for centuries. They are now grown in many parts of the world, including the United States, Europe, and Asia. Green cucumbers are typically grown in warm climates and require a lot of water. They are usually harvested when they are about 6-8 inches long.\\n\\n### Physical Characteristics\\n\\nGreen cucumbers have a smooth, thin skin that is dark'}\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke(input=\"green cucumbers\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id = \"gcp-langchain-450916\"\n",
    "location_id = \"global\"\n",
    "data_store_id = \"professional-documents_1739744440951\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/olawale/.cache/pypoetry/virtualenvs/genai-langchain-gcp-wbUR23ce-py3.11/lib/python3.11/site-packages/langchain_google_community/vertex_ai_search.py:364: UserWarning: Beta features are configured but beta=False. The following beta features will be ignored:['custom_embedding_ratio']\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file owner contributed to open source community development, tutorials, and software releases [1]. Their contributions include a package developed to help digital geoscientists with well log interpretation using Python [1]. Subsequent releases included machine learning support for well logs [1]. They also made technical contributions to OpendTect, dGB Earth Sciences [2]. A webinar showcasing these contributions received over a thousand views, becoming one of the highest viewed on the YouTube channel [2].\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_community import VertexAISearchSummaryTool\n",
    "vertex_search = VertexAISearchSummaryTool(\n",
    "    project_id=project_id, location_id=location_id,\n",
    "    data_store_id=data_store_id,\n",
    "    name=\"Vertex AI Agent Builder\",\n",
    "    description=\"RAG app on professional documents\"\n",
    ")\n",
    "query = \"What were the file owner's open source contributions?\"\n",
    "print(vertex_search.invoke(query))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom RAG Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my page\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "doc = Document(page_content=\"my page\",\n",
    "               metadata={\"source_id\": \"example.pdf\", \"page\": 1})\n",
    "print(doc.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I. Extract 2D image patches in various sizes from the seismic survey (32x32, 64x64\n",
      "(crosslines by depth slide) and run it through the unsupervised image classification\n",
      "algorithms.\n",
      "\n",
      "II. Determine how the images cluster and if consistent facies clusters can be obtained from\n",
      "\n",
      "the unsupervised image classification algorithms.\n",
      "\n",
      "III.\n",
      "\n",
      "Investigate if preprocessing steps (structural filter, denoising) improve the clustering\n",
      "\n",
      "results\n",
      "\n",
      "IV. Analyze dominant facies classes, map facies back to seismic. Construct an interactive\n",
      "dashboard for the manual definition of the facies clusters in the embedded space (e.g.\n",
      "t-sne umap etc).\n",
      "V. Port the 2D unsupervised and weakly supervised workflows into the 3D domain to\n",
      "investigate if 3D facies cubes can be clustered and investigated.\n",
      "\n",
      "1.3. Research Methodology\n",
      "The choice of method for this study is to use unsupervised machine learning methods to classify\n",
      "facies from 3D seismic surveys. State of the art models are used for this. Unlabelled 2D seismic\n",
      "image patches are run through unsupervised clustering algorithms and hyperparameters are tuned\n",
      "to optimize classification performance. Domain knowledge is used to label classified facies from\n",
      "unsupervised classification results. Classified seismic patches are mapped back to seismic\n",
      "volume and different workflow runs are evaluated from both machine learning and geological\n",
      "views. Figure 1.1 shows a pictorial representation of the workflow.\n",
      "\n",
      "2 gs://langchain-book-test-bucket/data_source1/data/Full Chapters Thesis.pdf\n",
      "1.3. Objectives of the study\n",
      "The objectives of this study are to;\n",
      "\n",
      "I.\n",
      "\n",
      "extract 2D image patches in various sizes from the seismic survey (32x32, 64x64\n",
      "(crosslines by depth slide) and run it through the unsupervised image classification\n",
      "algorithms,\n",
      "\n",
      "II. determine how the images cluster and if consistent facies clusters can be obtained from\n",
      "\n",
      "the unsupervised image classification algorithms,\n",
      "\n",
      "III.\n",
      "\n",
      "investigate if preprocessing steps (structural filter, denoising) improve the clustering\n",
      "results and;\n",
      "\n",
      "IV. analyze dominant facies classes, map facies back to seismic. Construct an interactive\n",
      "dashboard for the manual definition of the facies clusters in the embedded space (e.g.\n",
      "t-sne umap etc).\n",
      "\n",
      "1.4. Problem Definition\n",
      "\n",
      "Increasingly larger volumes of seismic data needs to be interpreted. Manual interpretations by\n",
      "human interpreters take months and tedious work to complete. Currently no 2D, let alone 3D\n",
      "facies, unsupervised or semi supervised mapping process exists that acts as a first and potentially\n",
      "second order facies guide to the discerning interpreter to aid and speed up seismic facies\n",
      "interpretation.\n",
      "\n",
      "1.5. Description of the Study Area\n",
      "The study area is located in the North Sea, Netherlands (offshore) as shown in Figure 1. The F3\n",
      "block is a block in the Dutch sector of the North Sea. The block is covered by 3D seismic that\n",
      "\n",
      "3 gs://langchain-book-test-bucket/data_source1/data/Full Chapters Thesis - Google Docs.pdf\n",
      "iv\n",
      "\n",
      "ACKNOWLEDGEMENT\n",
      "Special thanks to my project supervisor Dr. Mrs. Ojo for her help and proper guidance to get this\n",
      "thesis done effectively. I specially acknowledge the efforts and contributions of Peter Bormann\n",
      "for his immense and various contributions throughout the thesis work. I also appreciate my\n",
      "lovely parents for their continuous support through age-long parental care, financial assistance\n",
      "and prayers. I also thank all of my colleagues who have offered guidance in completing this\n",
      "\n",
      "work. gs://langchain-book-test-bucket/data_source1/data/Thesis-Frontpage.pdf\n"
     ]
    }
   ],
   "source": [
    "from langchain.retrievers import GoogleVertexAISearchRetriever\n",
    "\n",
    "vertex_search_retriever = GoogleVertexAISearchRetriever(project_id=project_id,\n",
    "                                                        location_id=location_id,\n",
    "                                                        data_store_id=data_store_id,\n",
    "                                                        max_documents=3)\n",
    "query: str = \"\"\"What were the results and findings for the unsupervised thesis project?\"\"\"\n",
    "result = vertex_search_retriever.invoke(query)\n",
    "for doc in result:\n",
    "    print(doc.page_content, doc.metadata[\"source\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '6b97359832fe439d1ed9cf53891f4162',\n",
       " 'source': 'gs://langchain-book-test-bucket/data_source1/data/Thesis-Frontpage.pdf'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'## Results and Findings of the Unsupervised Thesis Project\\n\\nBased on the provided context, the thesis project aimed to utilize unsupervised machine learning methods to classify facies from 3D seismic surveys. The project focused on extracting 2D image patches from the seismic survey in various sizes and running them through unsupervised image classification algorithms. The objectives were to:\\n\\n1. **Extract 2D image patches** in various sizes from the seismic survey (32x32, 64x64) and run them through the unsupervised image classification algorithms.\\n2. **Determine how the images cluster** and if consistent facies clusters can be obtained from the unsupervised image classification algorithms.\\n3. **Investigate if preprocessing steps** (structural filter, denoising) improve the clustering results.\\n4. **Analyze dominant facies classes**, map facies back to seismic, and construct an interactive dashboard for the manual definition of the facies clusters in the embedded space (e.g., t-sne umap).\\n5. **Port the 2D unsupervised and weakly supervised workflows** into the 3D domain to investigate if 3D facies cubes can be clustered and investigated.\\n\\nHowever, the provided context does not include information about the results and findings of the project. It only outlines the objectives and methodology. \\n\\nTherefore, I cannot answer your question regarding the results and findings of the unsupervised thesis project based on the provided context.\\n'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_google_vertexai import VertexAI\n",
    "\n",
    "template = \"\"\"\n",
    "    Answer the question based on the following context: {context}\n",
    "    Question: {question}\n",
    "    \"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "llm = VertexAI(model_name=\"gemini-pro\")\n",
    "chain = (\n",
    "    {\"context\": vertex_search_retriever,\n",
    "     \"question\": RunnablePassthrough()}\n",
    "     | prompt\n",
    "     | llm\n",
    "     | StrOutputParser()\n",
    ")\n",
    "chain.invoke(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query Expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "\n",
    "retriever_with_expansion = MultiQueryRetriever.from_llm(retriever=vertex_search_retriever,\n",
    "                                                        llm=llm)\n",
    "result = vertex_search_retriever.invoke(query)\n",
    "print(len(result))\n",
    "result_expanded = retriever_with_expansion.invoke(query)\n",
    "print(len(result_expanded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gs://langchain-book-test-bucket/data_source1/data/Full Chapters Thesis.pdf'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0].metadata[\"source\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gs://langchain-book-test-bucket/data_source1/data/Full Chapters Thesis.pdf',\n",
       " 'gs://langchain-book-test-bucket/data_source1/data/Thesis-Frontpage.pdf',\n",
       " 'gs://langchain-book-test-bucket/data_source1/data/Thesis-Frontpage-converted.pdf',\n",
       " 'gs://langchain-book-test-bucket/data_source1/data/Full Chapters Thesis.pdf',\n",
       " 'gs://langchain-book-test-bucket/data_source1/data/Full Chapters Thesis - Google Docs.pdf',\n",
       " 'gs://langchain-book-test-bucket/data_source1/data/Thesis-Frontpage.pdf',\n",
       " 'gs://langchain-book-test-bucket/data_source1/data/Full Chapters Thesis - Google Docs.pdf']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[result.metadata[\"source\"] for result in result_expanded]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/olawale/.cache/pypoetry/virtualenvs/genai-langchain-gcp-wbUR23ce-py3.11/lib/python3.11/site-packages/langchain_google_community/vertex_ai_search.py:364: UserWarning: Beta features are configured but beta=False. The following beta features will be ignored:['custom_embedding_ratio']\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 2\n"
     ]
    }
   ],
   "source": [
    "from langchain.retrievers.document_compressors import LLMChainFilter\n",
    "from langchain_google_community import VertexAISearchRetriever\n",
    "\n",
    "vertex_search_retriever_many = VertexAISearchRetriever(\n",
    "   project_id=project_id,\n",
    "   location_id=location_id,\n",
    "   data_store_id=data_store_id,\n",
    "   max_documents=30,\n",
    ")\n",
    "results_many = vertex_search_retriever_many.invoke(query)\n",
    "\n",
    "llm_compression = VertexAI(temperature=0,\n",
    "                           model_name=\"gemini-pro\")\n",
    "chain_filter = LLMChainFilter.from_llm(llm=llm_compression)\n",
    "# results_filtered = chain_filter.compress_documents(result_expanded, query)\n",
    "results_filtered_many = chain_filter.compress_documents(results_many, query)\n",
    "print(len(results_many), len(results_filtered_many))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gs://langchain-book-test-bucket/data_source1/data/Full Chapters Thesis.pdf2',\n",
       " 'gs://langchain-book-test-bucket/data_source1/data/Full Chapters Thesis - Google Docs.pdf3',\n",
       " 'gs://langchain-book-test-bucket/data_source1/data/Thesis-Frontpage.pdf4',\n",
       " 'gs://langchain-book-test-bucket/data_source1/data/Thesis-Frontpage-converted.pdf3',\n",
       " 'gs://langchain-book-test-bucket/data_source1/data/MY IT REPORT.docx',\n",
       " 'gs://langchain-book-test-bucket/data_source1/data/MY_IT_REPORT[2]-converted.pdf58',\n",
       " 'gs://langchain-book-test-bucket/data_source1/data/IT HEADINGS-converted.pdf5',\n",
       " 'gs://langchain-book-test-bucket/data_source1/data/REPORT_IGARRA[1]-converted.pdf36',\n",
       " 'gs://langchain-book-test-bucket/data_source1/data/Field_Trip_FrontPage[1]-converted.pdf4',\n",
       " 'gs://langchain-book-test-bucket/data_source1/data/Seminar-Frontpage-Updated-converted.pdf3']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[result.metadata[\"source\"] for result in results_many]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gs://langchain-book-test-bucket/data_source1/data/Full Chapters Thesis.pdf2',\n",
       " 'gs://langchain-book-test-bucket/data_source1/data/Full Chapters Thesis - Google Docs.pdf3']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[result.metadata[\"source\"] for result in results_filtered_many]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Results and Findings\n",
      "\n",
      "While the provided documents outline the objectives and methodology of the thesis project, they do not present the actual results and findings. \n",
      "\n",
      "Here's what we can glean from the documents:\n",
      "\n",
      "**Objectives:**\n",
      "\n",
      "* Extract 2D image patches from seismic surveys and run them through unsupervised image classification algorithms.\n",
      "* Determine how the images cluster and if consistent facies clusters can be obtained.\n",
      "* Investigate if preprocessing steps improve clustering results.\n",
      "* Analyze dominant facies classes and map them back to seismic data.\n",
      "* Develop an interactive dashboard for manual definition of facies clusters.\n",
      "* Port the 2D unsupervised workflow to the 3D domain to investigate 3D facies cubes.\n",
      "\n",
      "**Methodology:**\n",
      "\n",
      "* Unsupervised machine learning methods are used to classify facies from 3D seismic surveys.\n",
      "* Unlabelled 2D seismic image patches are run through unsupervised clustering algorithms.\n",
      "* Hyperparameters are tuned to optimize classification performance.\n",
      "* Domain knowledge is used to label classified facies from unsupervised classification results.\n",
      "* Classified seismic patches are mapped back to seismic volume.\n",
      "* Different workflow runs are evaluated from both machine learning and geological perspectives.\n",
      "\n",
      "**Missing Information:**\n",
      "\n",
      "* The documents lack information regarding the actual results and findings of the thesis project. \n",
      "* We don't know how the images clustered, whether consistent facies clusters were obtained, or how preprocessing steps impacted the results.\n",
      "* Information on dominant facies classes, their mapping back to seismic data, and the development of the interactive dashboard is also missing.\n",
      "* The success of the 3D workflow using 3D facies cubes remains unclear.\n",
      "\n",
      "**Therefore, to understand the results and findings of the unsupervised thesis project, you would need to consult additional resources beyond the provided documents.** This could include research papers, presentations, or the final thesis document itself. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "chain = (\n",
    "   {\"context\": vertex_search_retriever, \"question\": RunnablePassthrough()}\n",
    "   | RunnableLambda(lambda x: {\"context\": chain_filter.compress_documents(x[\"context\"], x[\"question\"]), \"question\": x[\"question\"]})\n",
    "   | prompt\n",
    "   | llm\n",
    "   | StrOutputParser()\n",
    ")\n",
    "\n",
    "\n",
    "print(chain.invoke(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
